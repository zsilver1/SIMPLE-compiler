(*
    A SIMPLE single layer perceptron
    to perform classification of handwritten
    digits (currently only supports binary classification)

    Rohit Bhattacharya
    rohit.bhattachar@gmail.com
*)

PROGRAM SIMPLEnet;

    (* declare some constants *)

    CONST numIterations = 2;
    CONST numTrain = 200; (* overall shud be 12664 *)
    CONST numTest = 100; (* should be 2115 *)
    CONST imgSize = 28*28;

    (* +1 is for a bias node *)
    CONST numHidden = imgSize + 1;

    (* declare data variables *)
    TYPE imgVector = ARRAY imgSize + 1 OF INTEGER;
    VAR trainData : ARRAY numTrain OF imgVector;
    VAR testData : ARRAY numTest OF imgVector;
    VAR trainLabels : ARRAY numTrain OF INTEGER;
    VAR testLabels : ARRAY numTest OF INTEGER;
    VAR currExample : imgVector;
    VAR prediction, error : INTEGER;

    (* weights of the network *)
    VAR weights : ARRAY numHidden OF INTEGER;

    (* counter variables *)
    VAR iter, i, j, k : INTEGER;
    VAR numCorrect : INTEGER;

BEGIN
    (* WRITE to confirm decls are done cuz its wicked slow
       when doing ALL the training and test examples *)
    WRITE 633;

    (* read training data *)
    WHILE i < numTrain DO
        trainData[i][0] := 1;
        j := 1;
	READ trainLabels[i];
	WHILE j < imgSize + 1 DO
	    READ trainData[i][j];
	    j := j + 1
	END;
	i := i + 1
    END;

    (* read testing data *)
    i := 0;
    WHILE i < numTest DO
        testData[i][0] := 1;
        j := 1;
	READ testLabels[i];
	WHILE j < imgSize + 1 DO
	    READ testData[i][j];
	    j := j + 1
	END;
	i := i + 1
    END;

    (* WRITE to confirm reading data is done *)
    WRITE 1234;

    (* start training loop *)
    WHILE iter < numIterations DO
        i := 0;
	WHILE i < numTrain DO
	    currExample := trainData[i];
	    j := 0;
	    prediction := 0;
	    WHILE j < numHidden DO
	        prediction := prediction + weights[j] * currExample[j];
		j := j + 1
	    END;

	    (* map the prediction to 0 or 1 *)
	    IF prediction >= 0 THEN
	        prediction := 1
	    ELSE
	        prediction := 0
	    END;

	    (* update weights *)
	    error := trainLabels[i] - prediction;
	    j := 0;
	    WHILE j < numHidden DO
	        weights[j] := weights[j] + error * trainData[i][j];
		j := j + 1
	    END;
	    (* WRITE prediction; *)
	    i := i + 1
	END;

        (* test the network *)
        i := 0;
	numCorrect := 0;
	WHILE i < numTest DO
	    currExample := testData[i];
	    j := 0;
	    prediction := 0;
	    WHILE j < numHidden DO
	        prediction := prediction + weights[j] * currExample[j];
		j := j + 1
	    END;

	    (* map the prediction to 0 or 1 *)
	    IF prediction >= 0 THEN
	        prediction := 1
	    ELSE
	        prediction := 0
	    END;

	    (*WRITE prediction;*)
	    (*WRITE testLabels[i];*)
            IF prediction = testLabels[i] THEN
	        (*WRITE prediction;*)
		(*WRITE testLabels[i];*)
	        numCorrect := numCorrect + 1
            END;
	    i := i + 1
	END;
	(* WRITE accuracy at given iteration *)
	WRITE iter;
	WRITE numCorrect;
	WRITE numTest;
	iter := iter + 1
    END;

    (* WRITE to confirm training is done *)
    WRITE 1437


END SIMPLEnet.
